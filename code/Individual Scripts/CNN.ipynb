{"cells":[{"cell_type":"markdown","metadata":{"id":"cUvIiQMhH7ec"},"source":["#### CNN Classification (Keras Tensorflow)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCnifXbGIYKw","executionInfo":{"status":"ok","timestamp":1714918967615,"user_tz":-330,"elapsed":79977,"user":{"displayName":"Abdul D","userId":"13894101110050450996"}},"outputId":"8234d85a-a4c5-4d44-8f3d-7fda8ed2b42d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8jPH3VjVH7eh","executionInfo":{"status":"ok","timestamp":1714919371718,"user_tz":-330,"elapsed":29872,"user":{"displayName":"Abdul D","userId":"13894101110050450996"}},"outputId":"d301cc6e-d23c-45a0-c9c9-760546de90c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/90\n","32/32 [==============================] - 1s 6ms/step - loss: 1.0928 - accuracy: 0.5030\n","Epoch 2/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.8377 - accuracy: 0.6386\n","Epoch 3/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.7043 - accuracy: 0.7008\n","Epoch 4/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.6548 - accuracy: 0.7369\n","Epoch 5/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.5671 - accuracy: 0.7580\n","Epoch 6/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.5159 - accuracy: 0.7871\n","Epoch 7/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.5140 - accuracy: 0.7942\n","Epoch 8/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.4731 - accuracy: 0.7972\n","Epoch 9/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.8052\n","Epoch 10/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8394\n","Epoch 11/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8313\n","Epoch 12/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8293\n","Epoch 13/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3685 - accuracy: 0.8333\n","Epoch 14/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8444\n","Epoch 15/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.3416 - accuracy: 0.8404\n","Epoch 16/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3422 - accuracy: 0.8474\n","Epoch 17/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3053 - accuracy: 0.8705\n","Epoch 18/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.3188 - accuracy: 0.8635\n","Epoch 19/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2904 - accuracy: 0.8675\n","Epoch 20/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2835 - accuracy: 0.8675\n","Epoch 21/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2685 - accuracy: 0.8755\n","Epoch 22/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2832 - accuracy: 0.8795\n","Epoch 23/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2804 - accuracy: 0.8805\n","Epoch 24/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2514 - accuracy: 0.8845\n","Epoch 25/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2429 - accuracy: 0.8865\n","Epoch 26/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2434 - accuracy: 0.8916\n","Epoch 27/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2324 - accuracy: 0.8886\n","Epoch 28/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2374 - accuracy: 0.8956\n","Epoch 29/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2136 - accuracy: 0.9106\n","Epoch 30/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2171 - accuracy: 0.9046\n","Epoch 31/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2150 - accuracy: 0.9096\n","Epoch 32/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2082 - accuracy: 0.9096\n","Epoch 33/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1952 - accuracy: 0.9177\n","Epoch 34/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1891 - accuracy: 0.9257\n","Epoch 35/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.2103 - accuracy: 0.9167\n","Epoch 36/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1877 - accuracy: 0.9137\n","Epoch 37/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1850 - accuracy: 0.9127\n","Epoch 38/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.2014 - accuracy: 0.9147\n","Epoch 39/90\n","32/32 [==============================] - 0s 9ms/step - loss: 0.1812 - accuracy: 0.9257\n","Epoch 40/90\n","32/32 [==============================] - 0s 8ms/step - loss: 0.1803 - accuracy: 0.9177\n","Epoch 41/90\n","32/32 [==============================] - 0s 9ms/step - loss: 0.1712 - accuracy: 0.9307\n","Epoch 42/90\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1491 - accuracy: 0.9418\n","Epoch 43/90\n","32/32 [==============================] - 0s 9ms/step - loss: 0.1780 - accuracy: 0.9187\n","Epoch 44/90\n","32/32 [==============================] - 0s 11ms/step - loss: 0.1677 - accuracy: 0.9197\n","Epoch 45/90\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1622 - accuracy: 0.9307\n","Epoch 46/90\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1681 - accuracy: 0.9287\n","Epoch 47/90\n","32/32 [==============================] - 0s 10ms/step - loss: 0.1556 - accuracy: 0.9297\n","Epoch 48/90\n","32/32 [==============================] - 0s 11ms/step - loss: 0.1543 - accuracy: 0.9327\n","Epoch 49/90\n","32/32 [==============================] - 0s 11ms/step - loss: 0.1439 - accuracy: 0.9367\n","Epoch 50/90\n","32/32 [==============================] - 0s 9ms/step - loss: 0.1541 - accuracy: 0.9337\n","Epoch 51/90\n","32/32 [==============================] - 0s 9ms/step - loss: 0.1674 - accuracy: 0.9317\n","Epoch 52/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1414 - accuracy: 0.9337\n","Epoch 53/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1376 - accuracy: 0.9408\n","Epoch 54/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1502 - accuracy: 0.9408\n","Epoch 55/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1296 - accuracy: 0.9388\n","Epoch 56/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1283 - accuracy: 0.9468\n","Epoch 57/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1266 - accuracy: 0.9448\n","Epoch 58/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1296 - accuracy: 0.9428\n","Epoch 59/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1412 - accuracy: 0.9458\n","Epoch 60/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1212 - accuracy: 0.9418\n","Epoch 61/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1214 - accuracy: 0.9568\n","Epoch 62/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1333 - accuracy: 0.9468\n","Epoch 63/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1200 - accuracy: 0.9538\n","Epoch 64/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1321 - accuracy: 0.9448\n","Epoch 65/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1208 - accuracy: 0.9548\n","Epoch 66/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1067 - accuracy: 0.9528\n","Epoch 67/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1201 - accuracy: 0.9518\n","Epoch 68/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1135 - accuracy: 0.9598\n","Epoch 69/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1077 - accuracy: 0.9558\n","Epoch 70/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1068 - accuracy: 0.9528\n","Epoch 71/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1237 - accuracy: 0.9488\n","Epoch 72/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1072 - accuracy: 0.9588\n","Epoch 73/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 0.9598\n","Epoch 74/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0931 - accuracy: 0.9598\n","Epoch 75/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1390 - accuracy: 0.9498\n","Epoch 76/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1038 - accuracy: 0.9608\n","Epoch 77/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0935 - accuracy: 0.9639\n","Epoch 78/90\n","32/32 [==============================] - 0s 7ms/step - loss: 0.1182 - accuracy: 0.9568\n","Epoch 79/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0906 - accuracy: 0.9679\n","Epoch 80/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1028 - accuracy: 0.9568\n","Epoch 81/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1108 - accuracy: 0.9528\n","Epoch 82/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.9548\n","Epoch 83/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0762 - accuracy: 0.9729\n","Epoch 84/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0983 - accuracy: 0.9629\n","Epoch 85/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.9679\n","Epoch 86/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.9618\n","Epoch 87/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0945 - accuracy: 0.9639\n","Epoch 88/90\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0825 - accuracy: 0.9669\n","Epoch 89/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.0888 - accuracy: 0.9639\n","Epoch 90/90\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1019 - accuracy: 0.9568\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 0.9229\n","Test score: 0.3407268226146698\n","Test accuracy: 0.922897219657898\n"]}],"source":["# coding= UTF-8\n","import numpy as np\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation\n","from keras.layers import Embedding\n","from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n","from keras.optimizers import SGD\n","from sklearn.model_selection import train_test_split\n","\n","# Load data\n","X = np.load(\"/content/drive/MyDrive/Speaker_Fluency/data/feat.npy\")\n","y = np.load('/content/drive/MyDrive/Speaker_Fluency/data/label.npy').ravel()\n","\n","# Fix random seed number\n","np.random.seed(7)\n","\n","number_of_features = len(X[1])\n","number_of_classes = 3\n","\n","# Split data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 233)\n","\n","# Need to reshape you data to have a spatial dimension for Conv1d to make sense\n","X_train = np.expand_dims(X_train, axis=2)\n","X_test = np.expand_dims(X_test, axis=2)\n","\n","# Neural Network Construction\n","model = Sequential()\n","\n","# Neural Network Architecture\n","# Using 1D Convolutions (approriate for audio files)\n","\n","# first layer has 64 convolution filters\n","model.add(Conv1D(64, 3, activation='relu', padding='same', input_shape = (number_of_features, 1)))\n","model.add(Conv1D(64, 3, activation='relu'))\n","model.add(MaxPooling1D(3))\n","model.add(Conv1D(32, 3, padding='same', activation='relu'))\n","model.add(Conv1D(32, 3, padding='same', activation='relu'))\n","model.add(GlobalAveragePooling1D())\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(number_of_classes, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","# Convert label to onehot\n","y_train = keras.utils.to_categorical(y_train - 1, num_classes= number_of_classes) # Converts a class vector (integers) to binary class matrix\n","y_test = keras.utils.to_categorical(y_test - 1, num_classes= number_of_classes)\n","\n","# Train Network\n","model.fit(X_train, y_train, batch_size=32, epochs=90)\n","\n","# Evaluate model's accuracy with test data\n","score, acc = model.evaluate(X_test, y_test, batch_size=32) # Computes the loss & accuracy based on the input you pass it\n","\n","print('Test score:', score) #loss\n","print('Test accuracy:', acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hd-fmbcnH7ek"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python2.7 Conda2","language":"python","name":"anaconda2_py27"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.14"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}